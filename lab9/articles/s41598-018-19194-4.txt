Symmetric Decomposition of Asymmetric Games
We introduce new theoretical insights into two-population asymmetric games allowing for an elegant symmetric decomposition into two single population symmetric games. Specifically, we show how an asymmetric bimatrix game (A,B) can be decomposed into its symmetric counterparts by envisioning and investigating the payoff tables (A and B) that constitute the asymmetric game, as two independent, single population, symmetric games. We reveal several surprising formal relationships between an asymmetric two-population game and its symmetric single population counterparts, which facilitate a convenient analysis of the original asymmetric game due to the dimensionality reduction of the decomposition. The main finding reveals that if (x,y) is a Nash equilibrium of an asymmetric game (A,B), this implies that y is a Nash equilibrium of the symmetric counterpart game determined by payoff table A, and x is a Nash equilibrium of the symmetric counterpart game determined by payoff table B. Also the reverse holds and combinations of Nash equilibria of the counterpart games form Nash equilibria of the asymmetric game. We illustrate how these formal relationships aid in identifying and analysing the Nash structure of asymmetric games, by examining the evolutionary dynamics of the simpler counterpart games in several canonical examples.
We are interested in analysing the Nash structure and evolutionary dynamics of strategic interactions in multi-agent systems. Traditionally, such interactions have been studied using single population replicator dynamics models, which are limited to symmetric situations, i.e., players have access to the same set of strategies and the payoff structure is symmetric as well1. For instance, Walsh et al. introduce an empirical game theory methodology (also referred to as heuristic payoff table method) that allows for analysing multiagent interactions in complex multiagent games2,3. This method has been extended by others and been applied e.g. in continuous double auctions, variants of poker and multi-robot systems1,4,5,6,7,8,9. Similar evolutionary methods have been applied to the modelling of human cooperation, language, and complex social dilemma’s10,11,12,13,14,15,16. Though these evolutionary methods have been very useful in providing insights into the type and form of interactions in such systems, the underlying Nash structure, and evolutionary dynamics, the analysis is limited to symmetric situations, i.e., players or agents can be interchanged and have access to the same strategy set, in other words there are no different roles for the various agents involved in the interactions (e.g. a seller vs a buyer in an auction). As such this method is not directly applicable to asymmetric situations in which the players can choose strategies from different sets of actions, with asymmetric payoff structures. Many interesting multiagent scenarios involve asymmetric interactions though, examples include simple games from game theory such as e.g. the Ultimatum Game or the Battle of the Sexes and more complex board games that can involve various roles such as Scotland Yard, but also trading on the internet for instance can be considered asymmetric.
There exist approaches that deal with asymmetry in multiagent interactions, but they usually propose to transform the asymmetric game into a symmetric game, with new strategy sets and payoff structure, which then can be analysed again in the context of symmetric games. This is indeed a feasible approach, but not easily scalable to the complex interactions mentioned before, nor is it practical or intuitive to construct a new symmetric game before the asymmetric one can be analysed in full. The approach we take in this paper does not require constructing a new game and is theoretically underpinned, revealing some new interesting insights in the relation between the Nash structure of symmetric and asymmetric games.
Analysing multiagent interactions using evolutionary dynamics, or replicator dynamics, provides not only valuable insights into the (Nash) equilibria and their stability properties, but also sheds light on the behaviour trajectories of the involved agents and the basins of attraction of the equilibrium landscape1,4,15,17,18. As such it can be a very useful tool to analyse the Nash structure and dynamics of several interacting agents in a multiagent system. However, when dealing with asymmetric games the analysis quickly becomes tedious, as in this case we have a coupled system of replicator equations, and changes in the behaviour of one agent immediately change the dynamics in the linked replicator equation describing the behaviour of the other agent, and vice versa. This paper sheds new light on asymmetric games, and reveals a number of theorems, previously unknown, that allow for a more elegant analysis of asymmetric multiagent games. The major innovation is that we decouple asymmetric games in their symmetric counterparts, which can be studied in a symmetric fashion using symmetric replicator dynamics. The Nash equilibria of these symmetric counterparts are formally related to the Nash equilibria of the original asymmetric game, and as such provide us with a means to analyse the asymmetric game using its symmetric counterparts. Note that we do not consider asymmetric replicator dynamics in which both intra-species (within a population) and inter-species interactions (between different populations) take place19, but we only consider inter-species interactions in which two different roles interact, i.e., truly asymmetric games20.
One of our main findings is that the x strategies (player 1) and the y strategies (player 2) of a mixed Nash equilibrium of full support in the original asymmetric game, also constitute Nash equilibria in the symmetric counterpart games. The symmetric counterpart of player 1 (x) is defined on the payoff of player 2 and vice versa. We prove that for full support strategies, Nash equilibria of the asymmetric game are pairwise combinations of Nash equilibria of the two symmetric counterparts. Then, we show that this property stands without the assumption of full support as well. Though this analysis does not allow us to visualise the evolutionary dynamics of the asymmetric game itself, it does allow us to identify its Nash equilibria by investigating the evolutionary dynamics of the counterparts. As such we can easily distinguish Nash equilibria from other restpoints in the asymmetric game and get an understanding of its underlying Nash structure.
The paper is structured as follows: we first describe related work, then we continue with introducing essential game theoretic concepts. Subsequently, we present the main contributions and we illustrate the strengths of the theory by carrying out an evolutionary analysis on four canonical examples. Finally, we discuss the implications and provide a deeper understanding of the theoretical results.
In the following, we first present our main findings, formally relating Nash equilibria in asymmetric 2-player games with the Nash equilibria that can be found in the corresponding counterpart games. We also examine the stability properties of the corresponding rest points of the replicator dynamics in these games. Then we experimentally illustrate these findings in some canonical examples.
In this section, we prove the following result: if (x, y) ∈ NE(A, B) (where x and y have the same support), then x ∈ NE(BΤ) and y ∈ NE(A). In addition, we prove that the reverse is true: if x ∈ NE(BΤ) and y ∈ NE(A) (where x and y have the same support) then (x,y) ∈ NE(A,B). We will prove this result in two steps (Theorem 1 and its generalization Theorem 2).
The theorems introduced apply to games where both players can play the same number of actions (i.e. square games). This condition can be weakened by adding dominated strategies to the player having the smallest number of actions (see the extended Battle of the Sexes example in the experimental section). Thus, without loss of generality, the theory will focus on square games. To begin, we state an important well-known property of Nash equilibria, that has been given different names; Gintis calls it fundamental theorem of Nash equilibria32. For sake of completeness, we provide a proof.
Let the strategy profile (x, y) be a Nash equilibrium of an asymmetric normal form game (A, B), and denote I
z
 = {i | z
i
 > 0} the support of a strategy z. Then,
This result is widely known. We provide it as it is a basis of our theoretical results and for the sake of completeness.
If x and y constitute a Nash equilibrium then, by definition zΤAy ≤ xΤAy,∀z. Let us suppose that there exists a z with I
z
 ⊂ I
x
 such that zΤAy < xΤAy. Then there is a i ∈ I
z
 ⊂ I
x
 satisfying (Ay)
i
 < xΤAy, and we get \({x}^{{\rm{{\rm T}}}}Ay=\sum _{i\in {I}_{x}}{x}_{i}{(Ay)}_{i} < \sum _{i\in {I}_{x}}{x}_{i}{x}^{{\rm{{\rm T}}}}Ay={x}^{{\rm{{\rm T}}}}Ay\), which is a contradiction, proving the first claim. The claim for B follows analogously.◽
Let the strategy x be a Nash equilibrium of a single population game A. Then,
The proof is similar to the proof of Property 1.◽
This property will be useful in the steps of the proofs that follow. We now present our first main result: a correspondence between the Nash equilibria of full support in the asymmetric game with those of full support in the counterpart games. Theorem 2 subsumes this result and we introduce this simpler version first for the sake of readability.
If strategies x and y constitute a Nash equilibrium of an asymmetric normal form game G = (S
1
, S
2
, A, B), with both x
i
 > 0 and y
j
 > 0 for all i, j (full support), and |S
1
| = |S
2
| = n, then it holds that x is a Nash equilibrium of the single population game BT and y is a Nash equilibrium of the single population game A. The reverse is also true.
This result follows naturally from Property 1 and is implied by Theorem 2.
We start by assuming that x and y constitute a full support Nash equilibrium of the asymmetric game (A, B). By Property 1 and since x and y have full support, we know that:
From this we also know that yTAy = (Ay)
i
 (since the (Ay)
i
 are equal for all I’s in the vector Ay, so multiplying Ay with yT will yield the same number \({{\rm{\max }}}_{i}\,{(Ay)}_{i}\)), and similarly (xTB)
i
 = xTBx (and thus (BTx)
i
 = xTBTx), implying that:
This concludes the proof.◽
For the first counterpart game this means that the players will use the y part of the Nash equilibrium of player 2 of the original asymmetric game, in the symmetric counterpart game determined by payoff table A. And similarly, for the second counterpart game this means that players will play according to the x part of the Nash equilibrium of player 1 of the original asymmetric game, in the symmetric game determined by payoff table B. As such both players consider a symmetric version of the asymmetric game, for which this y component and x component constitute a Nash equilibrium in the two new respective symmetric games.
In essence, these two symmetric counterpart games can be considered as a decomposition of the original asymmetric game, which gives us a means to illustrate in a smaller strategy space where the mixed and pure equilibria are located.
A direct consequence of Theorem 1 is the following corollary that gives insights on the geometrical structure of Nash equilibrium,
Combinations of Nash equilibria of full support of the games corresponding to the symmetrical counterparts of the original asymmetric game also form Nash equilibria of full support in this asymmetric game.
This is a direct consequence of Theorem 1.◽
The next theorem explores the case where the equilibrium is not of full support. We prove that the theorem stands if the strategies of both players have the same support. Indeed, the first theorem requires that both players play all actions with a positive probability, here we will only require that they play the actions with the same index with a positive probability. We say that x and y have the same support if the set of played actions I
x
 = {i | x
i
 > 0} and I
y
 = {i | y
i
 > 0} are equal.
Strategies x and y constitute a Nash equilibrium of an asymmetric game G = (S
1
, S
2
, A, B) with the same support (i.e. I
x
 = I
y
) if and only if x is a Nash equilibrium of the single population game BT, y is a Nash equilibrium of the single population game A and I
x
 = I
y
.
We start by assuming that x and y constitute a Nash equilibrium of same support (I
x
 = I
y
) of the asymmetric game (A, B). By Property 1, and since x and y have the same support, we know that:
Implying that yΤAy = xΤAy and xΤBx = xΤBy (by setting z = y and z′ = x). Then, from the Nash equilibrium condition we can write:
which implies that y is a Nash equilibrium of BΤ and x is a Nash equilibrium of A.
The proof of the other direction follows similar mechanics and uses Property 2. Let us now assume that y is a Nash equilibrium of BΤ and x is a Nash equilibrium of A with I
x
 = I
y
. Then, from Property 2 we have:
In particular we get yΤAy = xΤAy and xΤBx = xΤBy (by setting z = x and z′ = y). From the Nash equilibrium condition of the single population games we can write:
which concludes the proof.◽
Strategies x and y constitute a pure (strict) Nash equilibrium of an asymmetric normal form game G = (S
1
, S
2
, A, B), with support on the strategy with the same index in their respective strategy sets S
1
 and S
2
, if and only if, y and x are also pure (strict) Nash equilibria of the counterpart games defined by A,
and B,
This is a direct consequence of Theorem 2.◽
The theorems can only be used for equilibria in the counterpart games with matching supports (I
x
 = I
y
) from both players. One can work around this condition though by simply permuting the actions of one player in matrix A and B to study all configurations of supports of the same cardinality. To be precise, we need to analyze all the counterpart games defined by AΣ = AΣ and \({B}_{\Sigma }^{T}=(B{\rm{\Sigma }}{)}^{T}\) for all permutation matrices Σ. This technique is sufficient to study non-degenerate games, as in a non-degenerate game all Nash equilibria have a support of same size (in a non-degenerate game if (x, y) is a Nash equilibrium then |I
x
| = |I
y
|34).
We can now examine the stability of the pure Nash equilibria discussed in the previously derived theorems.
Strategy y is a strict Nash equilibrium of the first counterpart game defined by A and strategy x is a strict Nash equilibrium of the second counterpart game defined by B, if and only if, (x, y) is a locally asymptotically stable equilibrium and a two-species ESS of the asymmetric normal form game G = (S1, S2, A, B) with support on the strategy with the same index in their respective strategy sets S1 and S2.
This a direct consequence of Corollary 2. More specifically, from Corollary 2 we know that (x, y) is a strict Nash equilibrium of G. It has been shown that (x, y) is a strict Nash equilibrium of G iff it is a two-species ESS19,20,27.◽
Replicator Dynamics have proved to be an excellent tool to analyse the Nash landscape of multiagent interactions and distributed learning in both abstract games and complex systems1,2,4,6. The predominant approach has been the use of symmetric replicator equations, allowing for a relatively straightforward analysis in symmetric games. Many interesting real-world settings though involve roles or player-types for the different agents that take part in an interaction, and as such are asymmetric in nature. So far, most research has avoided to carry out RD analysis in this type of interactions, by either constructing a new symmetric game, in which the various actions of the different roles are joined together in one population23,24, or by considering the various roles and strategies as heuristics, grouped in one population as well2,3,8. In the latter approach the payoffs due to different player-types are averaged over many samples of the player type resulting in a single average payoff to each player for each entry in the payoff table.
The work presented in this paper takes a different stance by decomposing an asymmetric game into its symmetric counterparts. This method proves to be mathematically simple and elegant, and allows for a straightforward analysis of asymmetric games, without the need for turning the strategy spaces into one simplex or population, but instead allows to keep separate simplices for the involved populations of strategies. Furthermore, the counterpart games allow to get insight in the type and form of interaction of the asymmetric game under study, identifying its equilibrium structure and as such enabling analysis of abstract and empirical games discovered through multiagent learning processes (e.g. Leduc poker empirical game), as was shown in the experimental section.
A deeper counter-intuitive understanding of the theoretical results of this paper is that when identifying Nash equilibria in the counterpart games with matching support (including permutations of strategies for one of the players), it turns out that also the combination of those equilibria form a Nash equilibrium in the corresponding asymmetric game. In general, the vector field for the evolutionary dynamics of one player is a function of the other player’s strategy, and hence a vector field in one player’s simplex doesn’t carry much information as any equilibria you observe in it are changing with time as the other player is moving too. However, if you position the second player at a Nash equilibrium, it turns out that player one becomes indifferent between his different strategies, and remains stationary under the RD. This gives the unique situation in which the vector field plot for the second player’s simplex is actually meaningful, because the assumption of player one being stationary actually holds (and vice versa). This is what we end up using when establishing the correspondence of the Nash Equilibria in asymmetric and counterpart games, and why the single-simplex plots for the counterpart games are actually meaningful for the asymmetric game - but this is also why they only describe the Nash Equilibria faithfully, but fail to be a valid decomposition of the full asymmetric game away from equilibrium.
These findings shed new light on asymmetric interactions between multiple agents and provide new insights that facilitate a thorough and convenient analysis of asymmetric games. As pointed out by Veller and Hayward36, many real-world situations, in which one aims to study evolutionary or learning dynamics of several interacting agents, are better modelled by asymmetric games. As such these theoretical findings can facilitate deeper analysis of equilibrium structures in evolutionary asymmetric games relevant to various topics including economic theory, evolutionary biology, empirical game theory, the evolution of cooperation, evolutionary language games and artificial intelligence11,12,37,38,39,40.
Finally, the results of this paper also nicely underpin what is said in H. Gintis’ book on the evolutionary dynamics of asymmetric games, i.e., ‘although the static game pits the row player against the column player, the evolutionary dynamic pits row players against themselves and column players against themselves’32 (chapter 12, p.292). He also indicates that this aspect of an evolutionary dynamic is often misunderstood. The use of our counterpart dynamics supports and illustrates this statement very clearly, showing that in the counterpart games species play games within a population and as such show an intra-species survival of the fittest, which is then combined into an equilibrium of the asymmetric game.
