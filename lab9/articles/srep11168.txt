Experimental quantum annealing: case study involving the graph isomorphism problem
Quantum annealing is a proposed combinatorial optimization technique meant to exploit quantum mechanical effects such as tunneling and entanglement. Real-world quantum annealing-based solvers require a combination of annealing and classical pre- and post-processing; at this early stage, little is known about how to partition and optimize the processing. This article presents an experimental case study of quantum annealing and some of the factors involved in real-world solvers, using a 504-qubit D-Wave Two machine and the graph isomorphism problem. To illustrate the role of classical pre-processing, a compact Hamiltonian is presented that enables a reduced Ising model for each problem instance. On random N-vertex graphs, the median number of variables is reduced from N2 to fewer than N log2 N and solvable graph sizes increase from N = 5 to N = 13. Additionally, error correction via classical post-processing majority voting is evaluated. While the solution times are not competitive with classical approaches to graph isomorphism, the enhanced solver ultimately classified correctly every problem that was mapped to the processor and demonstrated clear advantages over the baseline approach. The results shed some light on the nature of real-world quantum annealing and the associated hybrid classical-quantum solvers.
Quantum annealing (QA) is a proposed combinatorial optimization technique meant to exploit quantum mechanical effects such as tunneling and entanglement1. Machines purportedly implementing a type of quantum annealing have recently become available2. While the extent of “quantumness” in these implementations is not fully understood, some evidence for quantum mechanical effects playing a useful role in the processing has been appearing3,4,5. Aside from the debate over quantumness, there are interesting questions regarding how to effectively solve a real-world problem using a quantum annealer. Quantum annealing-based solvers require a combination of annealing and classical pre- and post-processing; at this early stage, little is known about how to partition and optimize the processing. For instance, current quantum annealers have severe practical limitations on the size of problems that can be handled. Can the pre-processing algorithms be modified in order to improve scalability? A second question involves post-processing. Quantum annealers provide solutions to an “embedded” version of a problem involving physical qubits. Post-processing is generally required for translating these to solutions to the original problem involving logical qubits (aka variables). Occasionally, a chain of physical qubits representing a single variable resolves to an inconsistent state, a scenario known as a broken chain. Studies are needed regarding broken chains and the possibility of classical error correction during post-processing.
This article presents an experimental case study of quantum annealing and some of the factors involved in real-world solvers, using a 504-qubit D-Wave Two machine. An example of parsimonious pre-processing is considered, along with post-processing majority voting. Through experiments on a 504-qubit D-Wave Two machine, we quantify the QA success probabilities and the impact of the methods under study. We use the graph isomorphism (GI) problem as the problem of focus. The GI problem is to determine whether two input graphs G1,2 are in essence the same, such that the adjacency matrices can be made identical with a relabeling of vertices. This problem is an interesting candidate for several reasons. First, an accurate quantum annealing-based solver for GI has never been implemented. Second, quantum approaches can sometimes provide new insight into the structure of a problem, even if no speedup over classical approaches is achieved or even expected. Third, the GI problem is mathematically interesting; though many sub-classes of the problem can be solved in polynomial time by specialized classical solvers, the run time of the best general solution is exponential and has remained at  since 19836,7. The classical computational complexity of the problem is currently considered to be NP-intermediate8 and the quantum computational complexity of the problem is unknown. Graph isomorphism is a non-abelian hidden subgroup problem and is not known to be easy in the quantum regime9,10. Lastly, the GI problem is of practical interest. It appears in fields such as very large-scale integrated circuit design, where a circuit’s layout graph must be verified to be equivalent to its schematic graph11 and in drug discovery and bio-informatics, where a graph representing a molecular compound must be compared to an entire database, often via a GI tool that performs canonical labeling6.
This article relates to previous works as follows. A pre-print by King and McGeoch discusses tuning of quantum annealing algorithms, including the use of low-cost classical post-processing majority voting similar to what is evaluated in this article12. Our study goes further regarding pre-processing (designing a Hamiltonian to generate compact Ising models) and covers graph isomorphism rather than problems such as random not-all-equal 3-SAT. A work by Rieffel et al. maps real-world problems such as graph coloring to a D-Wave quantum annealer13. Regarding the graph isomorphism problem in particular, multiple attempts have been made using adiabatic quantum annealing. One of the first attempts assigned a Hamiltonian to each graph and conjectured that measurements taken during each adiabatic evolution could be used to distinguish non-isomorphic pairs14. A subsequent experimental study using a D-Wave quantum annealer found that using quantum spectra in this manner was not sufficient to distinguish non-isomorphic pairs15. A second approach converted a GI problem to a combinatorial optimization problem whose non-negative cost function has a minimum of zero only for an isomorphic pair. The approach required  problem variables and additional ancillary variables. It was numerically simulated up to N = 7 but not validated on a quantum annealing processor16. An alternative GI Hamiltonian was proposed by Lucas17.
To compare the resource requirements of the two proposed Hamiltonians, 100 pairs of graphs are used as inputs to Step 1 of the solver flow (Fig. 2), where 50 pairs are isomorphic and 50 are non-isomorphic for each size up to N = 100. Since H1 models a variable for each possible vertex pair, N2 variables are required by definition. Ising problems generated using H2 are found to use fewer variables than H1; scaling of the median problems fits to 0.748 N1.45. Incidentally, this indicates that most problems have fewer variables than with the Gaitan et al. approach, which entails  plus ancillary variables16. The variable scaling is illustrated in Fig. 3. In addition to the number of variables, a second resource metric is the number of non-zero interactions between variables; dense interactions make the minor embedding problem more difficult. We find that the scaling of variable interactions has been improved from O(N4) for H1 to O(N2.9) for H2 (where R2 = 0.9991).
Scaling of the number of Ising model variables.
H1 requires N2 variables by construction; H2 scales more efficiently—the median variable requirement fits to y = 0.748 N1.45 (R2 = 0.9995). Bars indicate the maximum and minimum. For reference, the green dotted line represents . Inputs are 50 isomorphic and 50 non-isomorphic pairs of G(N, 0.5) graphs.
Next, we compare the embeddability of the two approaches, in other words the extent to which Ising problems can be minor-embedded in a given processor graph. The processor of choice is the D-Wave Two Vesuvius-6 processor housed at USC ISI. At the time of this writing, the working graph contains 504 qubits and 1427 couplers. Embedding is attempted using the D-Wave findEmbedding() heuristic21 with default parameter values such as 10 “tries” per function call. As shown in Fig. 4a, embeddings are found for the majority of problems only for sizes N ≤ 6 when using H1, but sizes N ≤ 14 with H2 (Fig. 4a). The median number of qubits across all problems scales as O(N4.22) for H1 and has been reduced to O(N3.29) for H2 (Fig. 4b).
Embeddability when targeting the USC-LM Vesuvius processor’s 504-qubit, 1427-coupler working graph.
The inputs are 50 isomorphic and 50 non-isomorphic G(N, 0.5) pairs at each size. (a) Fraction of problems for which an embedding was found within 10 tries, using the D-Wave findEmbedding() heuristic. (b) Median number of utilized qubits among all 100 problems. H1 data points fit to y = 0.235 N4.22 (dotted line; R2 = 0.9996); H2 fits to 0.0723 N3.29 (R2 = 0.9955). A missing data point indicates no embedding was found for the median instance. The 65th and 35th percentiles are marked with bars (not always visible).
The accuracy of the solver described in the previous section was measured via trials conducted on a D-Wave Two Vesuvius quantum annealing processor. Several alternative strategies were compared—the use of Hamiltonians H1 vs. H2, running a single job per problem vs. multiple jobs and the use of chain majority voting during post-processing. Note that by construction of the Ising models using a penalty Hamiltonian, problems with non-isomorphic input graphs cannot achieve a zero energy state, regardless of annealing results. The main challenge for the solver is to find the zero energy state for isomorphic pairs. Thus, we first focus on the isomorphic case. One hundred isomorphic pairs were input into the solver for each size N from 3 to 20.
For one strategy in particular the zero energy state was always eventually achieved—the use of Hamiltonian H2 combined with multiple jobs and chain majority voting. Thus, with this strategy there were no false negatives and classification accuracy reached 100% of the embeddable problems, as shown in Table 1. For the most difficult problem, the zero energy state was achieved on the 9th job. All other strategies incurred false negatives. For the successful strategy, the expected total annealing time was calculated (as described in Methods). Results are shown in Fig. 5.
Total expected annealing time when using Hamiltonian H2, multiple jobs and classical majority voting.
Based on the quantum annealing results for 100 isomorphic-input problems. Missing data points indicate that no embedding was found and quantum annealing was not attempted.
For completeness, non-isomorphic pairs were run as well, using Hamiltonian H2 and chain majority voting. Since in the worst case nine jobs were required to correctly classify the isomorphic pairs above, nine jobs were submitted for each non-isomorphic problem. One hundred non-isomorphic G(N, 0.5) problems were tested at each size between N = 3 to 14; of the 1200 problems, embeddings were found for 1186. In addition, pairs of isospectral non-isomorphic graphs (PINGs) were tested. All N = 5 PINGs were tested (150 permutations), as well as 100 random N = 6 PINGs. As expected, none of the non-isomorphic problems achieved a zero energy state and thus none were classified as isomorphic. In other words, there were no false positives.
Several observations can be made from this case study. First, the formulation of the cost function (Hamiltonian) can have a noticeable impact on quantum annealing results. For the graph isomorphism problem, the baseline approach (embodied in Hamiltonian H1 and in [Lucas]17) blindly creates QUBO variables for every possible vertex pair, whereas the proposed Hamiltonian H2 is more parsimonious. Variable requirements decreased from N2 to fewer than N log2 N (Fig. 3) on the graph type under study, allowing larger problems to be solved (Fig. 4 and Table 1). Along with Rieffel13, this is one of the first quantum annealing studies to experimentally quantify the effect of alternative Hamiltonian formulations. One of the impacts of this observation is increased appreciation for the fact that all quantum annealing-based solvers are actually classical-quantum hybrids and that focus must be placed on effectively partitioning the processing and optimizing the classical portion. A caveat is in order—if the classical side is made to do too much work then the quantum annealing aspect becomes trivial and of little value. Further work is needed in identifying the specific strengths of annealing processors and in leveraging the two sides appropriately.
A second observation is that using chain majority voting during post-processing can in some cases provide a benefit. Previously, such majority voting was evaluated for a different set of problems (scheduling) and was not found to provide a significant benefit13. In our context, there were many problems for which the zero energy ground state solution was only achieved when using this post-processing; without this form of error correction (in other words, when all solutions containing a broken chain were discarded), false negatives occurred. For instance, at N = 12, 53 of 83 embedded problems were solved on the first job without using chain majority voting and an additional 12 problems were solved by applying chain majority voting (Table 1). Classical error correction strategies other than majority voting should be explored and assessed in future studies and their costs quantified.
To our knowledge, the evaluated solver is the first validated, experimental implementation of a QA-based graph isomorphism solver. While it ultimately classified every embeddable problem correctly and demonstrated clear advantages over the baseline approach, it has serious limitations as a graph isomorphism solver. The problem sizes are not competitive with those handled by classical solvers, which can handle G(N, 0.5) graphs with thousands of vertices6 and even for the hardest graph types can handle hundreds of vertices before running into difficulty22. Similarly, the scaling of the total annealing times (Fig. 5) is not competitive with classical scaling6. Ultimately, new approaches are likely needed if quantum annealing is to contribute to graph isomorphism theory or practice. Fortunately, the case study provides some new insight into experimental quantum annealing and contributes methods that have relevance beyond the GI problem. It is hoped that the experimental evaluation of alternative Hamiltonian formulations adds to the understanding of the factors affecting quantum annealing performance and that the demonstration of majority voting raises new questions about the role of post-processing for a variety of problems.
Quantum annealing experiments were performed on the D-Wave Two machine housed at USC ISI and operated by the USC-Lockheed Martin Quantum Computing Center. Experiments were conducted in October and November, 2014. The working graph of the machine’s Vesuvius-6 quantum annealing processor consisted of 504 qubits and 1427 couplers during this period. The pattern of working qubits is shown in Figure 6. The qubit temperature was estimated by the manufacturer to be 16 ± 1 mK. Additional processor specifications include a maximum anti-ferromagnetic mutual inductance of 1.33 and  amplitude of 7.5 ± 1 .
Physical layout of the working qubits in the USC-LM D-Wave Two Vesuvius-6 processor as of October 10, 2014.
504 working qubits (gray), 8 non-working (black). All 1427 couplers connecting working qubits are part of the working graph.
Simple undirected N-vertex graphs were constructed according to the Erdős-Rényi G(n, p) model20 with n = N and with the probability p of including each edge equal to 0.5. Non-isomorphic pairs were generated by creating two graphs as above and checking for non-isomorphism using the MATLAB graphisomorphism() function. Isomorphic pairs were generated by generating a single graph then applying a random permutation to arrive at the second graph. For each pair of input graphs, an Ising model was created using equation (4) or (5). Programming was performed using MATLAB R2014a win64 and the D-Wave MATLAB pack 1.5.2-beta2. The current version of the D-Wave sapiFindEmbedding() function cannot directly embed Ising models with more than one connected component (i.e. a set of variables that interact only with each other and not any of the remaining variables); therefore, models with this characteristic were not included in the input data. When attempting to generate 100 input pairs for each size, such disconnected models occurred no more than 4 times for each size N ≥ 14. Similarly, the heuristic cannot accept models with fewer than two variables, so in the rare case of a trivial Ising problem with fewer than two variables (e.g. a non-isomorphic pair with no matching degrees), dummy variables were added to the problem.
The hi values of the Ising problem were split evenly across each qubit in the associated chain in the embedded Ising problem. The Jij values of the Ising problem were assigned to a single coupler connecting two variable chains in the embedded problem. The magnitudes of the embedded h′ and J′ were scaled together such that the maximum magnitude reached 20% of the full range supported by the processor; the range of the embedded hi′ values was [−0.4, 0.4] and the range of the embedded Jij′ values coupling different variables was [−0.2, 0.2]. This 20% value was determined empirically to provide good performance on the median difficulty problem at the largest sizes. Subsequently, the Jij′ values connecting physical qubits within a chain were set to the maximum ferromagnetic value (−1). A single random spin gauge transformation2 was then applied to each embedded problem, with a gauge factor ai ∈ {−1, 1} associated with each qubit and transformation hi′ → ai hi′; Jij′ → ai aj Jij′. One job was submitted to the quantum annealer per embedded problem; some Ising problems were associated with multiple embedded problems and jobs. After each programming cycle, the processor was allowed to thermalize for 10 ms (the maximum supported by the machine). The annealing time was set to the minimum value of 20 μs. The number of annealing and readout cycles per programming cycle was 40000, which allowed the total job time to be within the limits of the machine (1 s). The readout thermalisation time was set to the default value of 0. Regarding error correction through majority voting of chains of physical qubits, ties were broken by choosing the spin up state. The probability of achieving the zero energy state on job k is denoted
When multiple jobs are required, we calculate the geometric mean in the style of Boixo et al.2:
The total annealing time required to reach 0.99 probability of success was calculated by multiplying the annealing time by the expected number of annealing cycles (repetitions R) using the formula2:
