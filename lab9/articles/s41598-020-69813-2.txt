Developing intelligent medical image modality classification system using deep transfer learning and LDA
Rapid advancement in imaging technology generates an enormous amount of heterogeneous medical data for disease diagnosis and rehabilitation process. Radiologists may require related clinical cases from medical archives for analysis and disease diagnosis. It is challenging to retrieve the associated clinical cases automatically, efficiently and accurately from the substantial medical image archive due to diversity in diseases and imaging modalities. We proposed an efficient and accurate approach for medical image modality classification that can used for retrieval of clinical cases from large medical repositories. The proposed approach is developed using transfer learning concept with pre-trained ResNet50 Deep learning model for optimized features extraction followed by linear discriminant analysis classification (TLRN-LDA). Extensive experiments are performed on challenging standard benchmark ImageCLEF-2012 dataset of 31 classes. The developed approach yields improved average classification accuracy of 87.91%, which is higher up-to 10% compared to the state-of-the-art approaches on the same dataset. Moreover, hand-crafted features are extracted for comparison. Performance of TLRN-LDA system demonstrates the effectiveness over state-of-the-art systems. The developed approach may be deployed to diagnostic centers to assist the practitioners for accurate and efficient clinical case retrieval and disease diagnosis.
Medical images are wellspring of learning on human life structures. These images are used to make visual illustrations of internal human body structure and pattern discovery for several types of clinical diagnosis such as brain tumor, breast, lung, and liver cancers. Generally, medical images are used for identification of particular aspect of affected tissue types and organs. Owing to human disease diversity and imaging modalities, it is challenging to classify the medical images compared to non-clinical images. The visual features of medical images are usually separated by subtle variation. For efficient and accurate disease diagnosis, radiologist requires several related clinical cases for analysis and interpretation of particular imaging modality. These modality images may also be used for teaching and demonstration purposes. Traditionally, specific modality images are retrieved manually from archives that is cumbersome and time-consuming processes. Manual annotation for retrieval is subjective and it does not represent image content properly, consequently it may mislead radiologist while analyzing new clinical cases. Archived medical image retrieval is critical due to the high cost of manual content annotation for tremendous image collections, variations in spellings, synonyms, and hyponyms1. Moreover, these images are acquired in different conditions, and associated information may be insufficient for interpretation and analysis2,3. The objective of a practitioner is to diagnose a disease based on similar archived clinical cases by employing the prior information and knowledge4.
Medical image archived databases provide cost-effective storage and convenient way compared to conventional text-based access over standard Picture Archiving and Communication Systems (PACS)5,6. Header of digital imaging and communication systems (DICOM) holds tags to interpret the observed body part and its modality7. This system automatically sets some of the tags as per the imaging protocol which is used to acquire the object image. Other tags are set manually by the medical expert/radiologists during routine documentation. This procedure is frequent and susceptible to error because some entries are either missed or not described automatically and precisely8.
Variety of imaging instruments are in practice to scan human body for disease diagnosis. For a clinician, modality is an essential characteristic to analyze human body anatomy and related clinical cases for an accurate diagnosis. Medical imaging archives are characteristically comprised of several types of modalities such as ultrasound, MRI, CT scan, PET, X-rays, etc. Retrieval technologies such as Yottalook and GoldMiner offering modality search facility, however modality information obtained by the image caption is annotated by the domain expert. Studies revealed that visual features might be useful for modality retrieval9. Several issues associated with modality based medical image retrieval systems. First, owing to the high modality diversity, a single algorithm cannot be capable to differentiate from medical archives10. Secondly, precise and absence of resilient dataset is challenging for the development and evaluation of an automated modality classification system. Hence, there is a vital need of an automatic and reliable system which effectively retrieves modality images from medical archives for disease diagnosis and rehabilitation process.
ImageCLEF is established for standardization of modality collection and classification11. CLEF Initiative labs provides an assessment campaign for organizing medical image modality classification challenges. The standard target of ImageCLEF is to support the domain of visual media examination, retrieval, and characterization. It works on imperative frameworks for appraisal of visual information recovery system that functioning in monolingual and cross-language settings. The modality classification task was initially presented in ImageCLEF-2010 campaign, where the total number of modalities limited to eight. Subsequently, data was extended to 18 and 31 in 2011 and 2012 respectively. The ImageCLEF campaign is helpful to enhance the retrieval and classification tasks.
The main objective of this research is to classify the medical images efficiently and accurately by exploiting the Deep TL features followed by linear discriminant analysis (LDA). For the development of modality classification models, we employed the challenging ImageCLEF-2012 medical image dataset12,13. For training and evaluation of the developed models, ImageCLEF has provided annotated dataset. Figure 1 shows the hierarchy of the 31 classes of ImageCLEF-2012 dataset.
Hierarchy of 31 modalities of ImageCLEF-2012 dataset12.
Extensive experiments are performed to evaluate and validate the usefulness of the developed approach. The approach is applied to classify multiclass problem using benchmark ImageCLEF-2012 medical image modality dataset. Details of dataset can be found in material section. We obtained Deep TL ResNet50 features to develop classification model in combination with LDA (TLRN-LDA) algorithm. Performance of the developed approach is compared with state-of-the-art approaches and hand-crafted features based classification using overall and class-wise measures. The effectiveness of the develop model is also evaluated by comparing with TL ResNet50 using softmax classifier.
Table 1 shows an average performance measures of the proposed approach in terms of accuracy, sensitivity, specificity, precision, F-score, and MCC are 0.88, 0.89, 0.99, 0.88, 0.88 and 0.88, respectively. From Table 1, it is inferred that each performance measure accomplished high average value more than 88%. This high performance indicates the usefulness of the developed approach for modality classification.
In multiclass problem, class-wise performance evaluation is inevitable. Figure 2 depicts class-wise accuracy of the proposed approach. From Fig. 2, it is observed that our model achieved the maximum and minimum class accuracies of 100% and 53%, respectively. Overall, most of the classes attained greater than 80% accuracy. However, classes ‘COMP’, and ‘GSYS’ provided an accuracy lower than average. Figure 3 shows class-wise F-score of the proposed model which successfully identified the positive classes with high precision.
Class-wise accuracy of the proposed TLRN-LDA.
Class-wise F-score of the proposed TLRN-LDA.
Training performance in terms of accuracy, sensitivity, specificity, precision, F-score, MCC, and class-wise accuracy of the developed approach is shown in supplementary material Figures S1, S2, and S3. Accuracy and loss for training and testing of TL-ResNet50 at different iterations are shown in Figure S4 and S5, respectively.
For accurate disease diagnosis, radiologist needs high true positive rate (TPR) and low false positive rate (FPR). ROC curve is one of the effective measures that simultaneously provide knowledge about TPR and FPR. Class-wise ROC curves are shown in Fig. 4. It is observed that most of the class curves are aligned with vertical axis and provided maximum AUC except classes ‘COMP’, and ‘GSYS’. This trend is similar to class-wise accuracy which is shown in Fig. 2. The proposed approach attained excellent performance in terms of average AUC (98.4%).
ROC curves of the TLRN-LDA for 31 classes.
The performance comparison of the developed TLRN-LDA and TL ResNet50-softmax classification is illustrated in Fig. 5a. It is observed from Fig. 5a that our approach demonstrated sufficient enhancement in each performance measure. For instance, accuracy is improved by 19% over TL ResNet50-softmax. The improved performance highlights that the proposed approach effectively learns the challenging multiclass ImageCLEF-2012 dataset. For fair comparison, we have included training and testing performance of the TLRN-LDA in Fig. 5b.
Performance comparison of the proposed approach (a) TLRN-LDA training and testing and (b) TLRN-LDA and ResNet50-softmax.
Table 2 shows performance comparison of the developed approach with state-of-the-art approaches on the same benchmark ImageCLEF-2012 dataset. The proposed approach achieved high accuracy of 87.9%. Whereas, visual and texture feature based SVM classification model offers a maximum accuracy of 78.6%. Our approach improved accuracy of 16.5% over the visual and texture based SVM model. To validate the effectiveness of the developed approach, we extracted several hand-crafted features such as SIFT, LBP, LTP, EHD, CEDD, color edge detector using wavelet transform and color histogram, and developed hybrid features based LDA classification model. It provided 71.4% accuracy which is 16.5% lower than TLRN-LDA. Again, performance of our approach outperformed over hand-crafted feature based model.
For accurate disease diagnosis, medical image modality classification is one of the challenging tasks to retrieve the related clinical cases from large medical repository. Practitioner can get benefit for better diagnostic, treatment and rehabilitation decisions through the use of modern retrieval technologies. In this regard, we developed an intelligent and effective modality classification approach which offers excellent performance. Usually, Deep learning technique requires large amount of annotated datasets for training and validation of a model. On the other hand, medical data is inherently available in small amount. For this, we exploited the learning capability of Deep learning with TL concept to develop the modality classification models. The developed approach offers improved performance and has capability to perform high classification on relatively small image modality dataset. Unlike traditional CNN architectures, the proposed approach was developed by combining the TL ResNet50 feature space with LDA technique. In LDA, the objective function of Eq. (5) optimizes the ratio of between and within-class variances and thereby guaranteed the maximum class separability. The linear combinations which maximize Eq. (5) produce low variance of the same class and high variance for different classes in the projected space. In LDA model development process, each class is considered as a separate class against all others (one vs all) and obtained merely one lower dimensional space for other classes to project their data on it. In this way, we exploited the useful properties of LDA such as low intra-class variance, high inter-class variance, and optimal decision boundaries. It has achieved improved performance compared to TL ResNet50-softmax for medical image modality classification. The proposed approach mainly composed of two main parts: (i) construction of TL ResNet50 model for optimal Deep feature extraction and (ii) development of LDA classifier.
The original residual network (ResNet) architecture with 50 layers (ResNet50) has been trained on standard ImageNet dataset having 1,000 classes. This dataset does not contain classes related to our problem i.e. medical image modality (ImageCLEF-2012). Misclassification is expected, if ImageCLEF2012 dataset is directly feed to ResNet50 originally trained on general images which do not have any medical image modality classes. To overcome this issue, we used TL concept in conjunction with ResNet50 to classify ImageCLEF-2012 dataset of 31 classes.
Analysis of Fig. 6 shows that the ImageCLEF-2012 dataset used in this study have five classes with less than ten samples whereas other classes have relatively more samples thus the dataset is highly skewed. Generally, it is assumed that classification models offer sufficient performance on classes having more training instances. From Figs. 2 and 6, it is observed that developed approach attained high classification accuracy of 100%, 98%, 100%, 83%, and 97% for ‘DSEC’, ‘DSEM’, ‘DSEE’, ‘GMAT’ and ‘DRPE’ classes, having relatively less data samples, respectively. On the other hand, ‘COMP’ and ‘GSYS’ classes have higher data samples of 49 and 48 respectively but for both classes developed approach provided low class-wise accuracy of 53% and 54%, respectively.
Class-wise distribution of ImgeCLEF-2102 dataset. Each class sample is randomly divided into training and testing of ratio 70%:30%, respectively.
It is evident that during the modeling process, performance of the model is increased with relatively smaller training instances while decreased with larger training instances. Owing to the high diversity of images in the dataset for ‘COMP’ and ‘GSYS’ classes, performance of the developed model is decreased. On the other hand, TLRN-LDA efficiently learned the patterns and offer high performance on those classes with small number of instances. It is observed that small data sample classes with high inter and low intra-class variances played helpful role in the model development process. On the other hand, relatively more misclassification occurs for those classes which having large data sample with high intra-class variance. Figures 3 and 4 also supported to this fact in terms of F-score, and ROC curves measures, respectively. It is evident from the ROC curves that the classes with lower accuracy attained less AUC. The model may offer sufficiently high performance, if one can overcome the intra-class variation.
The comparison of training (Supplementary Figs. S1, S2, and S3) and testing (Figs. 2, 3, 5) performance shows the similar trend of the developed models. It is observed that training and testing models provided low performance on classes ‘COMP’, and ‘GSYS’ which having high intra-class variances.
From Table 1, it is observed that on employing TL concept the proposed approach achieved improved classification accuracy of 87.9%. This indicates that the model successfully learned the features and weights on new dataset. Obviously, the residual learning capability of ResNet50 helps in obtaining optimal Deep features. The FC layer of ResNet50 is replaced and networks learned the weights according to ImageCLEF-2012 dataset of 31 classes. Deep features are obtained at ‘avg_pool’ layer of the ResNet50 model. These learned features are exploited for development of LDA classification model. To validate the effectiveness, performance comparison of the developed model with ResNet50-softmax is shown in Fig. 5. It revealed that our approach offers improved performance in terms of average accuracy, sensitivity, specificity, precision, F-score, and MCC by 18%, 15%, 5%, 16%, 15%, and 16% over the ResNet50-softmax model. The develop LDA classifier achieved better performance because it successfully explored the patterns of Deep features for small dataset whereas, ResNet50-softmax requires large amount of data for search space exploration.
The enhanced performance, in terms of accuracy (87.9%) of the developed approach is revealed compared to state of the approaches on the same ImageCLEF-2012 dataset27,28,31 (Table 2). Cao et al., from IBM multimedia analytics group was the winner of the ImageCLEF-2012 competition27. They reported 69.9% classification accuracy by performing data augmentation for class balancing, extracted several visual image features followed by SVM classification. Thus, in terms of accuracy, an improvement of 18.31% is evident compared to Cao et al. approach27. Dimitrovski et al. reported 78.6% accuracy on ImageCLEF-2012 dataset by extracting visual and textual feature fusion followed by SVM classification28. Thus, an improvement of 9.31% is found compared to Dimitrovski et al. model28. Herrera et al. from medGIFT group extracted several visual hand crafted features and remains the runner-up and reported 66.2% classification accuracy on the same dataset31. It is observed that in terms of accuracy, an improvement of 21.71% is found compared to Herrera et al.31 model31. Further, from Table 2, it is inferred that an improvement of 21.71% in performance of the developed approached compared to hybrid hand crafted features based classification (present study).
The approaches compared in Table 2 used same input ImageCLEF-2012 dataset (1,001 images) for development of models. However, our approach is differing with the compared approaches in two ways: (i) we used LDA classifier for final classification instead of softmax and (ii) splitting of training and testing datasets for model development and evaluation. In first case, we employed LDA classifier on Deep features for final classification that is helpful for obtaining improved image modality classification. In other case, to obtain better generalization, we subdivided the dataset (1,001 images) into two parts (70% training, 30% test) and then fivefold cross-validation data resampling technique is applied. The relationship between training and testing results indicate better generalization of the develop model.
The developed approach outperformed over previously developed hand craft feature based approaches. The superior performance of our approach is might be due to (i) extraction of optimal Deep image features at ‘avg_pool’ layer of ResNet50 (ii) better generalization of the developed model and (iii) utilization of LDA classifier for better discrimination.
Owing to the skewed nature of ImageCLEF-2012 dataset it is challenging to perform classification with high accuracy without any data augmentation. TL and fine-tuning employed on ResNet50 provided most optimal and discriminate features for the development of LDA classification. This high classification performance of the developed approach revealed that ResNet50 is successfully learned the medical image modality features and LDA classifier better learned inter-class and intra-class variances than softmax classification at relatively small dataset. Values of the evaluated measures indicated the effectiveness of the developed model. The proposed approach can be used as a tool for modality classification by the radiologists or information retrieval products.
Our developed framework could be implemented on new daily data. Moreover, in future, we are intending to deploy the developed system in hospital for daily use of modality image retrieval for disease diagnosis by radiologists. The implemented computer codes are available for downloading at our University site for modifications and experimentations. Now, ImageCLEF has diverted its tasks from modality classification to seperate combined figures in ImageCLEF-2015 and onward datasets. In other word, tasks for the newer version of ImageCLEF dataset are changed from independent modality classification to sub-figure separation instead of independent modality classification. However, in our future research plan, we are intending to implement the developed framework with modifications for the most recent data from ImageCLEF for automatic image captioning and scene understanding, medical visual question answering and decision support on tuberculosis.
