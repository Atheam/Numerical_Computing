A reputation economy: how individual reward considerations trump systemic arguments for open access to data
#https://www.nature.com/articles/palcomms201751
Open access to research data has been described as a driver of innovation and a potential cure for the reproducibility crisis in many academic fields. Against this backdrop, policy makers are increasingly advocating for making research data and supporting material openly available online. Despite its potential to further scientific progress, widespread data sharing in small science is still an ideal practised in moderation. In this article, we explore the question of what drives open access to research data using a survey among 1564 mainly German researchers across all disciplines. We show that, regardless of their disciplinary background, researchers recognize the benefits of open access to research data for both their own research and scientific progress as a whole. Nonetheless, most researchers share their data only selectively. We show that individual reward considerations conflict with widespread data sharing. Based on our results, we present policy implications that are in line with both individual reward considerations and scientific progress.
In 1942, when Robert K. Merton formulated his four norms that comprise the ethos of ethical science (universalism, communism, disinterestedness and organized skepticism), he probably did not think of researchers archiving their data in a public repository. However, at least two of his norms relate directly to open access to research data, which means that data and supporting materials are made publicly available online (Berliner Erklärung, 2003). These are communism, the idea that there is a common ownership of scientific goods (here data), and organized skepticism, the idea that every scientist has the duty to let other researchers scrutinize his or her work (Merton, 1973). Well-documented and openly available datasets allow organized skepticism by enabling the replicability of research (Leonhart and Maurischat, 2004; Evans, 2010; Klein et al., 2013; McNutt, 2014a; Fecher et al., 2016). In this regard, open access to research data is a translation of the Mertonian norms for an ethical and democratic science to the digital age and a potential cure for the replication crisis we currently see in many scientific disciplines (McNutt, 2014a, 2016; Maxwell et al., 2015). And it is for these reasons that open access to research data is currently mandated by prominent funding agencies and science policy makers (Organisation for Economic Co-operation and Development., 2007; Deutsche Forschungsgemeinschaft, 2012).
Numerous prominent German research organizations—we surveyed researchers in Germany—have advocated open access to research data in small science since the Berlin Decleration on Open Access (Max-Planck-Gesellschaft, n.d.). The largest German research funder, the German Research Association, has published a much-read guideline for making data available (DFG, 2009). In addition, the European commission is testing open access to research data as a funding condition in Horizon 2020, a large funding program that aims to foster research in Europe (European Commission, 2013).
Despite the broad consensus that open access to research data benefits the scientific enterprise, it is practiced only in moderation by academic researchers (Campbell et al., 2002; Alsheikh-Ali et al., 2011; Tenopir et al., 2011; Enke et al., 2012). The low willingness of researchers to provide access to the data underlying their research has been identified as a major problem for the scientific enterprise (Tenopir et al., 2011; Enke et al., 2012; Andreoli-Versbach and Mueller-Langer, 2014). Alsheikh-Ali et al. (2011) reviewed 500 research articles published in the 50 journals with the highest impact factor. They found that of the 50 journals, 44 (88%) had a data availability policy. Yet, of the 500 assessed papers, only 47 papers (9%) included a full dataset which was deposited online. Vlaeminck and Herrmann (2015) examined 346 journals in business and economics and found that only 49 journals mentioned a data availability policy (14.2%). Only few research funders actually require data management plans (Borgman, 2012). And in cases where open access to research data is successfully practiced, it is often a top-down community effort (Sawicki et al., 1993), a cooperative project (Abazajian et al., 2009), or an institutional service (for example, panel data). Which means that Merton’s norms are a world away from today’s academic practice.
So far, the discrepancy between the ideal of open access to research data and the actual behaviour of research professionals has only been assessed for single research fields and had not been subjected to any kind of cross field comparison. Based on a survey among 1564 mainly German researchers across disciplines, we examine if this problem holds true for multiple disciplines and what explains it. We find that data withholding can best be explained by strategic reputation considerations and misaligned incentives in the academic reward system. We conclude that a rethinking of the academic reward structure to offer more formal recognition for intermediate products, such as data, code and consultation/transfer services, would have a positive impact on research collaboration and ultimately the integrity of the scientific enterprise as a whole.
To make the results of our study more accessible we structured them by reference to the five research questions we introducted earlier.
Despite the fact that open access to research data is widely considered a way of fostering scientific progress and although it is promoted by science policy makers, few researchers make their data publicly available. To see how researchers view open access to data, one question battery targeted the researchers’ general opinion. Table 2 summarizes the results to this set of questions.
The results show a general consensus in the research community that open access to data benefits academic research and that researchers should make their data publicly available. Eighty-three per cent of the respondents agree that openly available research data is a major contribution to scientific progress. Seventy-six per cent of the respondents say that other researchers should make their data publicly available. The majority of the researchers in our survey sees no disadvantage in making data publicly available. Seventy-four per cent disagree that they are deterred from publishing articles if a journal requires the publication of data. Seventeen per cent of the researchers agree with the statement that sharing data brings more disadvantages than advantages. While the results may be influenced by social desirability, the clarity of the responses shows that open access to research data is considered beneficial for research in general and is not considered detrimental to the individual researcher who shares data.
Open access to research data can be understood as one form of data sharing. Therefore, this research question explores with whom researchers share their data, and hence, which particular forms of data sharing are common in small science. For this purpose, we asked the researchers if they themselves have already shared data with others and if so, with whom. Table 3 summarizes the responses to that question.
The results show that most researchers have shared data in the past, although most have done so selectively. Across disciplines, 13% of all respondents stated that they have shared research data publicly at least once in the past. In contrast, 16% of our respondents stated that they have never shared data with other researchers. This result is surprising, since previous research reported numbers below 10% for never having shared research data(Campbell et al., 2002; Tenopir et al., 2011). The numbers regarding the scope of sharing vary considerably. For example, 58% of the respondents state that they have shared data with colleagues whom they know personally, but only 6% of all respondents stated that they have shared data with commercial researchers. Data sharing is already common practice among researchers. However, it mainly occurs among colleagues that know each other, for example, in joint research projects. In contrast, open access to data is a practice that is far less common.
There are also interesting results regarding the discipline and gender. For example: 28% of the social scientists and economists say that they have never shared data, whereas only 9% of natural scientists never shared data. 25% of the female researchers have never shared data, compared with 13% of the male researchers (see Supplementary Appendix Table A.1).
This question explores whether there are any parameters that have an influence on the researchers’ behaviour in regards to open access to data. Out of an exploratory interest, we tested factors that influence the sharing behaviour of a researcher. The sharing behaviour is defined here as the willingness to make data publicly available and the actual experience of making data publicly available.
The results of the regression analysis show that there is no significant influence of a researchers age on his/hers willingness to make data publicly available and on whether the respondent has done so in the past. The same holds true for the status a researcher has reached and his/her experience in academic research. This result is surprising, since previous research suggested that senior researchers are more willing to share data than their younger colleagues (Tenopir et al., 2011).
Knowledge regarding data management has a positive effect on the data sharing behaviour. Researchers who know how to make data publicly available are significantly more willing to do so (P<0.008) and they are more likely to have done so in the past (P<0.001). Researchers who have used secondary data before are significantly more willing to make it available publicly (P<0.052). The results show that knowledge on data management and previous experience are good indicators for data sharing.
Publishing preferences have an effect on the data sharing behaviour. Researchers that value open access highly are significantly more likely to make their data publicly available (P<0.001; see Supplementary Appendix Table A.2). The fact that a journal has a high reputation and a fast publishing process have no significant influence (P=0.627, respectively, P=0.110).
There are also interesting descriptive results. Overall “only” 56% of the respondents say that they know where to find secondary data and 50% know where and how to publish research data. Natural scientists know more about where and how they can publish data than respondents from other disciplines. Researchers from engineering and agriculture know far less about where they can find secondary data for their research than respondents from other disciplines (see Supplementary Appendix Table A.3). Seventy-nine per cent of the respondents in our survey agree that reputation/impact is important when publishing research results. It is by far the most important criteria when publishing, followed by a fast publishing process with 52% agreement, and lastly open access, with an agreement level of 39% (see Supplementary Appendix Table A.4).
With this question we want to unravel the specific aspects that either stop researchers from providing open access to their data or that promote this form of data sharing.
By a wide margin, the most prominent concern researchers have is that “other researchers could publish before me” (80%; see Table 4); the test variable “to publish before sharing” (85%) is the second most important enabler for making data publicly available (see Supplementary Appendix Table A.5). Hence, most researchers would keep a dataset to themselves until they are sure they have published every aspect of it. Furthermore, 46% say the concern that their data could be misinterpreted prevents them from making it publicly available. Only a few researchers (12%) are concerned about being “criticized or falsified.” The latter is interesting since potential falsifications have been widely hypothesized as a reason not to make make data available (Longo and Drazen, 2016a).
The majority of the respondents (73%) disagree that criticism or falsification would prevent them from making data publicly available (Table 4). The effort that went into the data collection is considered a barrier to making data available for 59% of the researchers. They agreed with the statement “I would not share my data if the data collection required considerable effort.” However, researchers are more likely to withhold their data if the sharing itself is a major effort (Table 4). Overall the effort to make data available is the second biggest impediment we could find (only behind “other researchers could publish before me”).
Interestingly, despite the demand for more formal recognition, only a minority regards “Co- authorship” as a motivator. Across disciplines, 79% of the respondents say that data citation would motivate them to make data available to others; only 10% say it would not. Financial support for sharing data is considered a motivator by only 17% of the respondents and rejected by 65% of the researchers (see Supplementary Appendix Table A.5). The results indicate that researchers seek more formal recognition.
Despite the fact that the overall pattern in how the respondents evaluate statements are similar in all disciplines, there are some interesting differences. For example: 58% of the medical researchers see a co-authorship as an enabler for sharing but only 23% of the social scientists and economists and 21% of the humanities scholars. This result indicates that co-authorship for sharing data is accepted among medical researchers in contrast to all other disciplines (see Supplementary Appendix Table A.6).
Our last question explores use cases for secondary data. Here, we want to understand what researchers would use openly available data for. If there was no demand for secondary data, the argument for open research data in small science would be invalid. We, therefore, asked researchers if they have used secondary data before and for which purpose they used it. Across all disciplines, 69% of researchers have worked with secondary data before.
Social science has the highest rate of secondary data users, with 78% of social scientists using this kind of data followed by natural science at 69%. The lowest rate of secondary data users can be found in agricultural science with 58% (see Supplementary Appendix Table A.7). The majority of the researchers across disciplines prefer to use secondary data to address novel research questions than to verify results. This assessment is especially true for the social sciences, where 69% of the respondents would use secondary data for novel research questions and only 17% to replicate results. In comparison, in medicine, 48% of the respondents would use secondary data for novel research questions and 38% for replicating results (see Supplementary Appendix Table A.8).
Our standardized online survey covers questions on data collection, data management and data sharing/withholding practices of academic researchers from a broad variety of disciplines. The survey was conducted in October and November 2014.
To diminish the perceived intrusiveness, fear of disclosure and social desirability effects we use an online survey (Tourangeau and Yan, 2007). The survey contains closed multiple-choice questions as rating scales. It covers questions on sociodemographics, the individual working context of the researcher, publication preferences, common impediments and incentives for sharing data, and expectations for using secondary data (Fecher et al., 2014).
The full survey can be found on the project’s GitHub page (https://github.com/data-sharing/persistent/tree/master/dsa-03/). The survey instrument is based on a previous study, consisting of a systematic review of data sharing studies and a secondary data user survey (Fecher et al., 2015b).
We conducted two pretest rounds, the first with researchers on the usability and comprehensibility of the survey, and the second with experts on data archiving and data reuse. The pretests led to minor changes in the wordings of the questions and to a shorter survey. We contacted every faculty head of 60 German universities and asked them to distribute the survey to researchers in their faculty. We selected the universities based on the number of students and chose the 20 largest, the 20 smallest and 20 medium-sized ones. Additionally, we contacted researchers from the four biggest German research organizations, the Max Planck Society, the Leibniz Association, the Helmholtz Association and the Fraunhofer Gesellschaft, and uploaded a link to the survey on our project website and on the website of the German Data Forum. In our mails to the faculty heads and in the introductory text of the survey, we specifically addressed researchers that work with data. That being said, our sample is a convenience sample and not representative of the entire population of academic researchers in Germany or worldwide.
Overall, 2661 people started the questionnaire, but not all respondents finished it. We excluded respondents who did not answer any questions about their status, employer and discipline and those who had answered <20% of the questions. We were left with 1564 valid entries—which represents about 59% of all respondents who started the survey (Fecher et al., 2016). Eighty-eight per cent of the respondents work in German institutions, while 12% of the respondents work in other countries. The relatively high number of researchers outside Germany in the sample can be explained by respondents reached via mailing lists and website postings. The average age of the respondents is 38 years. Figure 1 shows the composition of our sample by academic status and disciplinary background.
Sample composition by career stage, discipline and gender.
We derived the categories for the scientific disciplines from the “Statistische Jahrbuch” (Germany’s statistical yearbook) (Statistisches Bundesamt and Statistisches Bundesamt, 2016). In Table 1 we compare the numbers for the six disciplines (natural science, social science, humanscience, engineering, humanities and agricultural science) in total and separately for professors and researchers (with or without a PhD). The comparison highlights a disciplinary bias in the data. We over-sampled in particular the social sciences (31% in our sample versus 15% in the statistical yearbook) and the natural sciences (34% versus 25%). Vice versa, human sciences (12% versus 27%) and engineering (8% versus 18%) are underrepresented.
The discussion in the results section is mostly based on univariate frequency tables. We used a 5-point Likert scale that was depicted with equal spaces between the response options (Bentler and Chou, 1987).
In addition, the appendix contains further tables including two binominal logistic regression models (Supplementary Appendix Table A.2). We prepared the binominal regressions out of an exploratory interest, which means that we did not optimize the models. Even if the models are not optimized, they provide more information than the sole frequency tables because they enable us to control for multiple external factors.
The choice for the dependent and independent variables derives from our systematic review on academic data sharing that we conducted in preparation of the survey (Fecher et al., 2015b). Based on the systematic review, we designed a framework for the discussion of data sharing in academia including aspects like the perspective of the data producer, the secondary data user, or the influence of the community and legal systems. This framework also identifies enablers and barriers for data sharing. In the survey, we focused on those factors that concern the data producer.
The first model uses the dependent variable “willingness to share data with a broad audience” and the second model uses “has shared data with a broad audience in the past.” We differentiate between these two since the actual willingness to disclose a dataset has been shown to differ from the actual researcher behaviour. Regarding the independent variables, we include various factors, identified in the systematic review. These factors comprise the status of the researcher (for example, student, researcher or professor), the discipline, the experience in using secondary data, the research aims, structural knowledge regarding data sharing, opinions on data sharing and the kind of data (qualitative, quantitative, sensitive) that is mostly used. Furthermore, we control for sex and age. For those independent variables, which concern opinions, we assessed approval or rejection of a statement by grouping the responses into two categories.
