Application of Quantum Annealing to Nurse Scheduling Problem
Quantum annealing is a promising heuristic method to solve combinatorial optimization problems, and efforts to quantify performance on real-world problems provide insights into how this approach may be best used in practice. We investigate the empirical performance of quantum annealing to solve the Nurse Scheduling Problem (NSP) with hard constraints using the D-Wave 2000Q quantum annealing device. NSP seeks the optimal assignment for a set of nurses to shifts under an accompanying set of constraints on schedule and personnel. After reducing NSP to a novel Ising-type Hamiltonian, we evaluate the solution quality obtained from the D-Wave 2000Q against the constraint requirements as well as the diversity of solutions. For the test problems explored here, our results indicate that quantum annealing recovers satisfying solutions for NSP and suggests the heuristic method is potentially achievable for practical use. Moreover, we observe that solution quality can be greatly improved through the use of reverse annealing, in which it is possible to refine returned results by using the annealing process a second time. We compare the performance of NSP using both forward and reverse annealing methods and describe how this approach might be used in practice.
Among non-deterministic polynomial time (NP)-hard problems, timetabling or rostering problems represent a number of practically important examples. For example, in operations research, the nurse scheduling problem (NSP) arises when finding the optimal schedule for a set of available nurses over a fixed timetable of shifts. Solutions to NSP are required to respect hard constraints, such as days off and minimum availability, as well as soft constraints, such as minimum shift assignments, for each nurse. Examples of NSP are often cast as linear or quadratic programming problems, depending on the nature of the constraints, but they may also be formulated in terms of unconstrained optimization and solved using search methods, including tabu search.
Quantum annealing (QA) is a metaheuristic method for solving combinatorial optimization problems derived from the principles of quantum mechanics1. QA operates by driving the Hamiltonian dynamics of an initial quantum state to a sought-after final state that represents the minimum energy configuration of an encoded optimization problem2. In the limit that the dynamics are strictly adiabatic and the Hamiltonian sufficiently complex, this coincides with the universal model of adiabatic quantum computing3,4. In practice, however, the adiabatic condition is rarely obtained and the guarantee that the true solution will be recovered is lost. Instead, these quasi-adiabatic dynamics yield the sought-after final state with some non-unit probability and it remains open as to when such behavior can provide a computational advantage2,5.
We demonstrate the use of QA to solve NSP and we evaluate its efficiency and accuracy for this problem from empirical results. Our approach uses the commercial quantum annealer available from D-Wave Systems to implement several hard constraints. The D-Wave 2000Q is a commercially available quantum annealing device based on superconducting flux qubits designed to solve quadratic unconstrained binary optimization (QUBO)6. It uses the principles of QA operating in the presence of a transverse-Ising Hamiltonian by encoding the problem into a sparsely connected graph expressing the hardware interactions. By reducing NSP to QUBO form and then embedding this problem into the D-Wave processor, we use QA to recover candidate solutions for different problem instances.
Previous applications of QA to unconstrained optimization span a broad variety of topics7,8,9,10,11,12,13,14, while some efforts have investigated closely related timetabling problems, such as the job-shop problem15. The distinguishing features of NSP include the multiple hard constraints, which make the problem difficult to address for conventional numerical solvers16. Equally challenging is the effort to recover approximately optimal solutions, which may fail to find the true minimum with some parameterized tolerance.
Our interest lies in casting NSP as a combinatorial optimization problem in order to validate the capabilities of QA. This may be seen as a first step toward developing quantum-enhanced solvers for other scheduling problems as well. However, the question as to whether QA satisfies the question of quantum computational advantages cannot be addressed here. In addition to limitations on the existing hardware, in both capacity and control17, there is poor theoretical understanding of the computational power for QA generally. Prior analyses have suggested that NSP and other classical combinatorial optimization problems belong to the complexity class stoqAQC, for which the relationship to the uniquely quantum complexity class BQP is not yet established2. These so-called stoquastic problems may be solved efficiently by strictly classical methods, but this is also unknown5. However, there is a clear potential for quantum advantage for non-stoquastic problems, which do not correspond to NSP or other combinatorial optimization problems18.
Our presentation is organized as follows. Sec. 2 defines NSP formally in terms of the hard and soft constraints considered here; Sec. 3 introduces QA specialized to the D-Wave 2000Q in terms of a transverse Ising Hamiltonian that encodes an NSP instance. Results from evaluating various problem instances on the 2000Q processor are summarized in Sec. 4, and the influence of reverse annealing to improve these results are discussed. Lastly, we conclude in Sec. 6 with comments for future work.
Using the Ising model for NSP, we solve this combinatorial optimization problem with the D-Wave 2000Q. Our implementations use the randomized embedding algorithm based on work by Cai, Macready and Roy and implemented in the D-Wave software toolchain24. We first discuss results obtained using forward annealing and then with reverse annealing. For our studies, we fix the annealing time for a single sample to 200 μs and we collect 1000 samples per problem instance to estimate the solution frequency. We present results for N = 3 and 4 nurses and D = 5–14 days. Throughout our study, we fix the parameters γ = 0.3 and λ = 1.3, and for the soft nurse constraints, we use the simplest example with \({h}_{1}(n)=1\), \({h}_{2}(d)=1\), \(E(n)=1\), \(W(d)=1\) and the penalty \(a=7/2\). The results of simulated annealing show that ground states were found well when those vales of a, γ and λ were used (see Fig. 2).
A graphical representation of the computed schedules are shown in Fig. 1 of two solutions obtained from forward annealing for an instance with \(N=3\) and \(D=4\). The schedule in Fig. 1 (left) satisfies all the constraints of this NSP instance, whereas the result in Fig. 1 (right) does not satisfy the nurse constraint that every nurse has an assignment. Consequently, solution (left) minimizes the energy of the Ising spin model, i.e., it represents a ground state, while the result in (right) is necessarily higher due to the penalty term. Similar results are obtained for all the instances tested here, and in the following, we present statistical estimates for the frequency with which the computed schedules satisfy all the constraints. Of course, the ground state may be degenerate and multiple satisfying schedules are possible.
Graphical examples of the computed shift schedules for the case of \(N=3\) nurses for \(D=4\) days. A black square indicates that a nurse is scheduled to work. The horizontal axes labels the days and the vertical axes labels the nurses. The left figure represents a schedule that satisfies all the constraints, while the right figure represents a schedule that fails to satisfy the soft nurse constraint of every nurse being assigned some days of work.
We first consider the quality of solutions obtained by forward annealing. Figure 2 presents the probability of finding a ground state with D-Wave 2000Q (left) and simulated annealing (right) for the case of N = 3 and 4 over a schedule of D days. While there is significant probability to recover completely satisfying solutions for smaller schedules, we observe that the probability to satisfy all constraints falls below our sampling level for larger schedules. In particular, we did not observe completely satisfying solutions from D-Wave 2000Q for N = 4, D = 10, 11, 12, 13, 14, whereas some ground states were obtained with D-Wave 2000Q for N = 3, D = 11, 12, 13, 14 and for N = 4, D = 9. Regarding the results by simulated annealing, we observed ground states for all (N, D). Comparing those results, we may say simulated annealing has a considerable advantage.
The probability of finding a ground state of the Hamiltonian by using D-Wave 2000Q (left) and simulate annealing (right) for (blue) \(N=3\) and (red) \(N=4\) with respect to the number of days D in the schedule. Each error bar is generated by the standard deviation (1000 samples for 10 shots for D-Wave 2000Q and 500 annealing times 10 shots for SA).
We next evaluate the deviation of computed solutions from the completely satisfying solution using the Hamming distance. For these calculations, we express the schedules as ordered binary vectors of size ND and we sum the elements of their inner product to calculate the number of position in which they agree. Subtracting this number from ND yields the Hamming distance, which measure the number of position in which the vectors disagree. In particular, a value of zero indicates exact agreement between the computed schedule and the observed ground state solution. Figure 3 plots the Hamming distance between consecutive solutions obtained by means of the D-wave processor. It is apparent from these statistics that the average Hamming distance is well below the maximum value if ND but significantly greater than 0 for all forward annealing solutions. We will present a comparison with reverse annealing solutions in the next section.
The Hamming distance between consecutive forward annealing solutions with respect to number of schedule days for (blue) \(N=3\) nurses and (red) \(N=4\) nurses. Error bars are based on the standard deviation.
We study the performance of reverse annealing when using the schedules computed by forward annealing. Reverse annealing is a heuristic methods to improve the frequency with which a computed solution satisfies the problem constraints. The procedure basically consists of the following three steps: (1) evolving the Hamiltonian H(T) to an intermediate value H(sT) where \(s\in [0,1]\), (2) pausing the evolution for a hold period ht, and then (3) evolving from H(sT) to H(T). The first step begins from a candidate solution and prepares an intermediate computational state of the quantum annealer, while the pause period enables the intermediate computational states to non-adiabatically mix with nearby instantaneous eigenstates due to the applied transverse field. The final step yields to potentially new computed solution state.
An example of a reverse annealing schedule used in our study is shown in Fig. 4. The schedule reverses to \(s=0.6\) at time 2 μs, holds for ht = 10 μs and then anneals forward at 12 μs to end at 14 μs. Though there are various choices of the target s and hold time ht, we have found the heuristic to work for our problem instances when \(s\in [0.6,0.8]\) and \({h}_{t}\in \{10,50,100\,\mu s\}\).
A reverse annealing schedule used in our study plotted with respect to the evolution of the dimensionless parameter s.
We apply reverse annealing to two different sets of forward annealing solutions. The first use of reverse annealing processes randomly chosen samples from the distribution of forward annealing solution reported in the previous section. Using the schedule shown in Fig. 4, we show in Fig. 5 that the probability of finding a completely satisfying solution of the NSP instance decreases and, in some cases, vanishes. The probabilities for N = 4, D = 11, 12, 13, 14 are exactly zero. While it is noted that solutions were successfully improved for most of the cases by reverse annealing, the average success rate decreased. By this methodology, the probability of finding ground states is highly related to the frequency distribution of forward annealing, since initial inputs of reverse annealing are randomly chosen. Comparing Fig. 5 with the probability of forward annealing given in Fig. 2, we see that the accuracy is not always improved by reverse annealing. This is understood as follows. When accuracy is improved by reverse annealing, this is because the relatively many forward annealing solutions which are close to ground states are obtained and those solutions are frequently picked up as initial inputs of reverse annealing.
Probability of finding the ground states of the NSP Hamiltonian by reverse annealing. Each error bar is generated by the standard deviation (1000 samples times 10 shots for each problem).
We examine the corresponding Hamming distance between consecutive solutions computed with reverse annealing in Fig. 6, which shows the mean Hamming distance and their standard deviation. Comparing Fig. 6 with Fig. 3, we notice that overall reverse annealing decrease the mean and the standard deviation of the Hamming distance becomes close to 0, which implies that reverse annealing successfully refined solutions and grouped them together.
Hamming distance between consecutive reverse annealing solutions (1000 samples for each problem). Error bars are based on the standard deviation.
We now discuss application of reverse annealing to the low-lying energy states of the forward annealing solution distribution. These states represent the best solutions obtained from forward annealing and, therefore, may be the most likely to be effected by the process. This approach can be useful to estimate the essential effect of reverse annealing, since it is natural to ask whether reverse annealing works well when an initial state already close to the true ground state.
We used the lowest energy solution from each forward annealing distribution as the initial state of reverse annealing. Figure 7 presents the probability of finding a solution that completely satisfies the constraints of the NSP instance from reverse annealing with these initial states. In a process of analyzing data, we noticed that even if a satisfying solution is used as the initial input, it is not guaranteed that computed solution will be the same state. There are many local minima and reverse annealing may get trapped in such local minima depending on the schedule parameters. We find that the accuracy is close to 100% when the ground state is used for an input, otherwise the probability decreases. Figure 7 is based on different lowest energy states, some of which are ground states, of forward annealing.
Probability of finding the ground states of the NSP Hamiltonian by reverse annealing. Error bars are based on the standard deviation (1000 samples times 10 shots for each problem).
Some ground states were successfully obtained by reverse annealing even though the initial input was not a ground state. This shows that it is possible to improve solution quality by reverse annealing for the case of using the low-lying energy states as input. However for the \(N=4\) case, ground states were not observed for D = 10, 11, 12, 13, 14. Figure 8 show the mean Hamming distance and the standard deviation for these results. Both statistics are greatly reduced compared to the forward annealing results as expected from the improved accuracy.
The Hamming distance of consecutive reverse annealing solutions (1000 samples for each problem). Error bars are based on the standard deviation.
A lower value of s_target corresponds to a larger transverse field, which leads to a broader search of the solution space. A greater value of hold_time (microseconds) implies that the reverse anneal is given more time to explore, which leads to a broader and deeper search of the solution space.
The D-Wave 2000Q is based on quantum annealing, which is a derivative of adiabatic quantum optimization. The latter is based on the time-dependent Schrodinger equation
where \(\psi (T)\) denotes the quantum mechanical wave function of an underlying physical system and H(t) is the time-dependent Hamiltonian that drives the dynamics. A generic form of this Hamiltonian is
with \(t\in [0,T]\) and T the final evolution time. The schedules A(t), B(t) are monotonic and satisfy \(A(0)=1\), \(B(0)=0\) and \(A(T)=0\), \(B(T)=1\). Therefore, the quantum state \(\psi (0)\) evolves under an interpolation from H0 to H1 in order to prepare the final state \(\psi (T)\). Assuming the initial state is an eigenstate of H0, then the adiabatic theorem promises that the quantum state will remain an instantaneous eigenstate of H(t) provided the dynamics evolve sufficiently slow. The latter condition may be enforced by choice of the annealing time T or the schedules. Consequently, we may select the final Hamiltonian H1 to represent a computational problem in which the eigenstates encode a well-defined solution. More precisely, we will focus on the case in which the ground state encodes the computational solution.
Let \({s}_{i}^{x}\), \({s}_{i}^{z}\) be Pauli spin operators at sites. The D-Wave 2000Q implements an initial Hamiltonian expressed as
where V is a set of spin sites, and a final Hamiltonian that takes the Ising spin model form
where Jij describe the interaction between sites i, j and hi are the weights of the linear terms. The resulting time-dependent Hamiltonian corresponds to the well-known transverse field Ising model which is used widely in statistical physics to describe complex spin systems. Finding the ground state of the Ising model itself is known to be NP-Hard and, therefore, this Hamiltonian is capable of expressing a broad variety of combinatorial optimization problems including, as we show below, NSP. By contrast, the ground state of H0 is easy to deduce.
Notwithstanding the premise of adiabatic quantum optimization, the technical challenges of reliably preparing a quantum physical system in a pure, zero-temperature quantum state prevent these ideals from being realized in practice. Rather, the behavior of the 2000Q is better approximated by a mixed quantum state evolving as an open system. In addition to the limits on controllability, there is more general concern that knowing the optimal annealing schedule and duration require a priori information about the solution itself. Therefore, quantum annealing is most often treated as a heuristic that may be applied with good accuracy in certain situations.
In our examples below, we interface with the quantum annealer by providing a logical representation of the Ising spin model H1 to be solved. Additional steps address the transformation of the logical input into a physical representation which can be embedded into the hardware19. This step, known as minor embedding, depends strongly on the connectivity of the vertex set V and the sparsity of the chimera layout20,21. Consequently, additional auxillary spin variables may be introduced during embedding to ensure logical connections are satisfied22. In addition, the ability to express the logical parameters, Ji,j and hi, is limited by the dynamic range of the hardware control.
The 2000Q offers a variety of controls for modifying the annealing time and schedules that determine the quantum dynamics leading to solution. Forward annealing corresponds to the process of driving the quantum system from the initial Hamiltonian H0 to the final Hamiltonian H1 and then performing measurements. We use forward annealing to compute the outcome of a given problem instance and we repeat this process many times to estimate the frequency with which computed solutions are observed. Reverse annealing builds on the result of a forward anneal by first initializing the processor to a previously computed result and then reversing the Hamiltonian dynamics to anneal backward. This process reintroduces the transverse field and potentially prepares a new, intermediate quantum state. The process is then completed by annealing forward in time to the final Hamiltonian. We investigate the relative accuracy of both forward and reverse annealing to solve instances of NSP.
A common approach to casting combinatorial optimization as an Ising model is to first express the problem as unconstrained optimization and, more specifically, as quadratic unconstrained binary optimization (QUBO)23. The QUBO form offers a direct mapping into the Ising model using a simple change of variable from binary to bipolar representation. We take this approach to formulate NSP as a QUBO problem with respect to minimization and then transform to the equivalent Ising model.
Consider a set of N nurses labeled as \(n=1,\ldots ,N\) and a schedule consisting of D working days labelled as \(d=1,\ldots ,D\). Using the binary variable \({q}_{n,d}\in \{0,1\}\), let \({q}_{n,d}=1\) specify the assignment of nurse n to day d. We then consider specific instances of the shift and nurse constraints discussed above. For the hard shift constraint, we require that the schedule must ensure at least 1 nurse is assigned each working each day. For the hard nurse constraint, the schedule must ensure no nurse works two or more consecutive days, while the soft nurse constraint requires that all nurses should have approximately even work schedules.
We construct objective functions that correspond to each shift and nurse constraint and then use the sum of these terms to express the QUBO form. We introduce composite indices \(i(n,d)\) and \(j(n,d)\) as functions of the nurse n and the day d. We construct the hard nurse constraint by introducing a symmetric, real-valued matrix J such that \({J}_{i(n,d),j(n,d+1)}=a\) and zero otherwise. The positive correlation constant a enforces the nurse constraint by penalizing a schedule for nurse n to work two consecutive days. The resulting objective function is quadratic, i.e., \({J}_{i,j}{q}_{i}{q}_{j}\), and takes its minimal when the hard nurse constraint is satisfied. Note that the nurse constraint can be modified by changing the entries of the matrix J.
We express the hard shift constraint in terms of the required workforce W(d) needed on each day d and the level of effort E(n) available from each nurse n. We seek an equality solution for this constraint by introducing a quadratic function that penalizes schedules with too many or too few nurses assigned. We take a similar approach for the soft nurse constraint by introducing a quadratic penalty for failing to account for nurse preferences in the work schedule. We use F(n) to specify the number of work days that each nurse wishes to be scheduled and \(G(n,d)\) to define a the preference for nurse n to work on day d.
As a simplified example of the soft nurse constraint, we decompose the preference function into the product \(G(n,d)={h}_{1}(n){h}_{2}(d)\), in such a way that
In addition, they can also have options whether they may work on weekend/night or not by tuning h2(d):
The formulation can be more sophisticated by including three-shift systems, distinction of weekdays and weekends regarding burden, or day-off request with priority. We simply require the minimum duty days F(n) for all nurses n are equal to or greater than [D/N], where [x] (\(x\in {\mathbb{R}}\)) means the integer part of x.
Composing these individual terms into a single objective function yields the QUBO form
where the positive real-valued numbers λ and γ tune the relative significance of each term. The objective function has its minimum when all the constraints are satisfied and takes on a positive value otherwise. We will assume that the functions E(n), F(n) and W(d) are integer-valued functions of n or d but this is not required. We will require the minimum duty days F(n) for all nurses n are equal to or greater than [D/N], where [x] (\(x\in {\mathbb{R}}\)) means the integer part of x.
We next transform the QUBO expression in Eq. (7) into an equivalent Ising spin model. This requires changing from the binary variables qi to the bipolar spin variable \({s}_{i}=2{q}_{i}-1\). The resulting quadratic terms are then collected to match the form of the Ising spin model in Eq. (4). Notably, the connectivity between spin sites is determined by the relatively sparse nurse constraints J and F(n) as well as the shift constraints set by E(n), W(d), and G(n, d).
